{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit"
    },
    "interpreter": {
      "hash": "c72a629dba5ae9edebcad565c17c3988d814021371aabb3db62cb04d2b10dbfe"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrismoroney/natural-language-processing/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mjBoJAJFIzP",
        "outputId": "b74b04ea-11b1-4ac9-d23c-c16fc458ef45"
      },
      "source": [
        "!gdown --id 10Yv6xUd1ufDilPcLdhR8L-zQZX5yNwSZ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10Yv6xUd1ufDilPcLdhR8L-zQZX5yNwSZ\n",
            "To: /content/dem-vs-rep.zip\n",
            "100% 9.29M/9.29M [00:00<00:00, 29.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFgDGWhFIzQ"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = './dem-vs-rep.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x27rSbjIFIzS"
      },
      "source": [
        "train_tweets = os.path.join('./dem-vs-rep/train.csv')\n",
        "test_tweets = os.path.join('./dem-vs-rep/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDgxi79_FIzT",
        "outputId": "f38e4df2-9cef-42fc-d87f-ed05d5ae55f8"
      },
      "source": [
        "import pandas\n",
        "train_df = pandas.read_csv(train_tweets)\n",
        "test_df = pandas.read_csv(test_tweets)\n",
        "print(train_df[:1])\n",
        "print(test_df[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Party         Handle                                              Tweet\n",
            "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
            "      Party        Handle                                              Tweet\n",
            "0  Democrat  RepAdamSmith  Today the House passed an omnibus spending bil...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcBmjqHzdRpg"
      },
      "source": [
        "import string\n",
        "\n",
        "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
        "             \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
        "             \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\",\n",
        "             \"he\", \"hed\", \"hes\", \"her\", \"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
        "             \"hows\", \"i\", \"id\", \"ill\", \"im\", \"ive\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\",\n",
        "             \"lets\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\",\n",
        "             \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"shed\", \"shell\", \"shes\", \"should\",\n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\",\n",
        "             \"there\", \"theres\", \"these\", \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\",\n",
        "             \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\",\n",
        "             \"what\", \"whats\", \"when\", \"whens\", \"where\", \"wheres\", \"which\", \"while\", \"who\", \"whos\", \"whom\", \"why\",\n",
        "             \"whys\", \"with\", \"would\", \"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\", \"yourself\",\n",
        "             \"yourselves\"]\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys0Evl0tFIzT"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_tweets = []\n",
        "train_labels = []\n",
        "\n",
        "for i in range(len(train_df.index)):\n",
        "  pre_tweet = train_df.iloc[i]['Tweet']\n",
        "  post_tweet = \"\"\n",
        "  for word in pre_tweet.split():\n",
        "    if word not in stopwords:\n",
        "      post_tweet += word + \" \"\n",
        "  train_tweets.append(post_tweet)\n",
        "  party = (train_df.iloc[i]['Party'])\n",
        "  if party == 'Democrat':\n",
        "    train_labels.append(0)\n",
        "  else:\n",
        "    train_labels.append(1)\n",
        "\n",
        "test_tweets = []\n",
        "test_labels = []\n",
        "\n",
        "for i in range(len(test_df.index)):\n",
        "  pre_tweet = train_df.iloc[i]['Tweet']\n",
        "  post_tweet = \"\"\n",
        "  for word in pre_tweet.split():\n",
        "    if word not in stopwords:\n",
        "      post_tweet += word + \" \"\n",
        "  test_tweets.append(post_tweet)\n",
        "  party = (test_df.iloc[i]['Party'])\n",
        "  if party == 'Democrat':\n",
        "    test_labels.append(0)\n",
        "  else:\n",
        "    test_labels.append(1)\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAa3vfScFIzU",
        "outputId": "0348d2c3-bfc3-43ec-a2a4-9db4902fb743"
      },
      "source": [
        "print(len(train_tweets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKgnXe0ZFIzU",
        "outputId": "8ffadfa3-9100-41af-8e47-249cb2bef5e2"
      },
      "source": [
        "print(train_tweets[:2])\n",
        "print(train_labels[:2])\n",
        "\n",
        "print(test_tweets[:2])\n",
        "print(test_labels[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Today, Senate Dems vote #SaveTheInternet. Proud support similar #NetNeutrality legislation House… https://t.co/n3tggDLU1L ', 'RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher one several recognized @RepDarrenSoto National Teacher Apprecia… ']\n",
            "[0 0]\n",
            "['Today, Senate Dems vote #SaveTheInternet. Proud support similar #NetNeutrality legislation House… https://t.co/n3tggDLU1L ', 'RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher one several recognized @RepDarrenSoto National Teacher Apprecia… ']\n",
            "[0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddWGkvdsFIzU"
      },
      "source": [
        "vocab_size = 69701\n",
        "embedding_dim = 16\n",
        "max_length = 200\n",
        "padding_type='post'\n",
        "trunc_type='post'\n",
        "OOV_token = \"<OOV>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3U2oa7kFIzU"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=OOV_token)\n",
        "tokenizer.fit_on_texts(train_tweets)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_tweets)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_tweets)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vU1iOWnFIzV",
        "outputId": "f81eb350-2cd2-4691-cc2e-1d99e747272f"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(decode_review(train_padded[0]))\n",
        "print(train_tweets[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "today senate dems vote savetheinternet proud support similar netneutrality legislation house… https t co n3tggdlu1l ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "Today, Senate Dems vote #SaveTheInternet. Proud support similar #NetNeutrality legislation House… https://t.co/n3tggDLU1L \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGM9M0wuFIzV",
        "outputId": "40ef6cc2-1ac6-4f4d-c874-1f8513912c4d"
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 16)           1115216   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 19206     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,134,429\n",
            "Trainable params: 1,134,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw221_uOFIzV",
        "outputId": "70dbb0d3-bbfa-46b2-9874-4950ae781674"
      },
      "source": [
        "num_epochs = 20\n",
        "model.fit(train_padded, train_labels, epochs=num_epochs,\n",
        "          validation_data=(testing_padded, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2160/2160 [==============================] - 39s 18ms/step - loss: 0.2327 - accuracy: 0.9194 - val_loss: 0.2940 - val_accuracy: 0.9437\n",
            "Epoch 2/20\n",
            "2160/2160 [==============================] - 42s 20ms/step - loss: 0.1087 - accuracy: 0.9690 - val_loss: 0.3567 - val_accuracy: 0.9465\n",
            "Epoch 3/20\n",
            "2160/2160 [==============================] - 43s 20ms/step - loss: 0.0712 - accuracy: 0.9805 - val_loss: 0.4885 - val_accuracy: 0.9527\n",
            "Epoch 4/20\n",
            "2160/2160 [==============================] - 41s 19ms/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.5619 - val_accuracy: 0.9520\n",
            "Epoch 5/20\n",
            "2160/2160 [==============================] - 38s 18ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.6255 - val_accuracy: 0.9528\n",
            "Epoch 6/20\n",
            "2160/2160 [==============================] - 42s 20ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.8059 - val_accuracy: 0.9530\n",
            "Epoch 7/20\n",
            "2160/2160 [==============================] - 42s 19ms/step - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.7018 - val_accuracy: 0.9529\n",
            "Epoch 8/20\n",
            "2160/2160 [==============================] - 42s 20ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.7520 - val_accuracy: 0.9530\n",
            "Epoch 9/20\n",
            "2160/2160 [==============================] - 43s 20ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.8680 - val_accuracy: 0.9537\n",
            "Epoch 10/20\n",
            "2160/2160 [==============================] - 43s 20ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.8226 - val_accuracy: 0.9538\n",
            "Epoch 11/20\n",
            "2160/2160 [==============================] - 43s 20ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.8999 - val_accuracy: 0.9537\n",
            "Epoch 12/20\n",
            "2160/2160 [==============================] - 43s 20ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.8901 - val_accuracy: 0.9537\n",
            "Epoch 13/20\n",
            "2160/2160 [==============================] - 42s 20ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.9372 - val_accuracy: 0.9537\n",
            "Epoch 14/20\n",
            "2160/2160 [==============================] - 44s 20ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.9862 - val_accuracy: 0.9537\n",
            "Epoch 15/20\n",
            "2160/2160 [==============================] - 43s 20ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 1.0601 - val_accuracy: 0.9537\n",
            "Epoch 16/20\n",
            "2160/2160 [==============================] - 45s 21ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.1252 - val_accuracy: 0.9537\n",
            "Epoch 17/20\n",
            "2160/2160 [==============================] - 44s 20ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 1.2127 - val_accuracy: 0.9536\n",
            "Epoch 18/20\n",
            "2160/2160 [==============================] - 47s 22ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 1.1408 - val_accuracy: 0.9537\n",
            "Epoch 19/20\n",
            "2160/2160 [==============================] - 49s 23ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 1.0728 - val_accuracy: 0.9526\n",
            "Epoch 20/20\n",
            "2160/2160 [==============================] - 44s 20ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 1.1679 - val_accuracy: 0.9529\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a6f7a4f28f0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cEcfLI_FIzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674b704f-3598-4516-aed7-f1b0074a81cf"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(69701, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Input statement below </h1>\n",
        "<p> Insert a sentence down below, then run the remaining cells to clasify your statement </p>\n"
      ],
      "metadata": {
        "id": "hNrjqVFZxcii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [\"There are too many shootings in the US. We need change.\"]"
      ],
      "metadata": {
        "id": "k11nbuDhxhYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p> Run the remaining cells to determine the model's interpretation of a democratic or repulican statement <p>"
      ],
      "metadata": {
        "id": "f7edUQ3Jxj28"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk0WBvOYZ68W",
        "outputId": "74995a05-aeee-4d3e-ca05-210bf9c9151b"
      },
      "source": [
        "sequence = tokenizer.texts_to_sequences(sentence)\n",
        "print(sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[250, 923, 1286, 87, 2470, 32, 8, 24, 13, 58, 520]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mg-SF-QaKcA",
        "outputId": "4d2ee37d-46f8-462c-e1e1-cd8163e100cb"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "print(\"Result:\", model.predict(padded)[0][0])\n",
        "print()\n",
        "result = \"\"\n",
        "if model.predict(padded)[0][0] < 0.37:\n",
        "  result = \"Republican\"\n",
        "elif model.predict(padded)[0][0] > 0.63:\n",
        "  result = \"Democratic\"\n",
        "else:\n",
        "  result = \"Neutral\"\n",
        "print(\"Output:\", result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "Result: 0.003382092\n",
            "\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Output: Republican\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Interpretting the results <h1>\n",
        "<p> Look at the value in your cell. The value is a number between 0 and 1.\n",
        "\n",
        "\n",
        "*   If your number is closer to 0, your statement aligns closer to a ***Republican*** statement\n",
        "*   If your number is closer to 1, your statement aligns closer to a ***Democratic*** statement"
      ],
      "metadata": {
        "id": "jjrVJaBIyKS2"
      }
    }
  ]
}